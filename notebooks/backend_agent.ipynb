{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff77b03-4c44-44a2-a549-6ced2f211f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import(\n",
    "    PyPDFLoader, TextLoader, UnstructuredWordDocumentLoader, ArxivLoader\n",
    ")\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3a724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads .env file into environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"‚úÖ API key loaded:\", bool(api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./notebooks/uploads\", exist_ok=True)\n",
    "os.makedirs(\"./notebooks/vectorstore\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeaa744",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "plan_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "draft_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "final_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75149025",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectordb = Chroma(persist_directory=\"./vectorstore\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    intent: str\n",
    "    context: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    final: str\n",
    "    research_mode: str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20134e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardrails\n",
    "FORBIDDEN_TOPICS = [\"politics\", \"religion\", \"violence\", \"illegal\", \"personal\"]\n",
    "\n",
    "def is_out_of_scope(query: str) -> bool:\n",
    "    q = query.lower()\n",
    "    return any(t in q for t in FORBIDDEN_TOPICS)\n",
    "\n",
    "SYSTEM_ORCHESTRATOR = \"\"\"\n",
    "You are the Orchestrator Agent.\n",
    "Classify the user's query as:\n",
    "- 'general' ‚Üí for simple factual questions.\n",
    "- 'research' ‚Üí for analytical or academic topics.\n",
    "- 'blocked' ‚Üí if unrelated to factual or academic work.\n",
    "Respond ONLY with one word: general, research, or blocked.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_ANALYZER = \"\"\"\n",
    "You are the Analyzer Agent.\n",
    "Search for factual and academic information, summarize objectively,\n",
    "and include short source indicators like (source: arxiv, local doc, or web).\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PLANNER = \"\"\"\n",
    "You are the Plan Writer Agent.\n",
    "Create a clear academic outline (Introduction, Body, Conclusion)\n",
    "based on the given question and retrieved context.\n",
    "Do NOT write the essay ‚Äî only the plan.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_WRITER = \"\"\"\n",
    "You are the Draft Writer Agent.\n",
    "Expand the plan into a coherent, well-structured essay (400‚Äì600 words)\n",
    "with academic tone, logical flow, and factual precision.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_CRITIC = \"\"\"\n",
    "You are the Critic Agent.\n",
    "Review the essay for clarity, coherence, structure, and evidence quality.\n",
    "Offer concise suggestions for improvement (under 150 words).\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_FINALIZER = \"\"\"\n",
    "You are the Final Drafter Agent.\n",
    "Polish the essay for grammar, tone, and academic conciseness.\n",
    "Ensure clear formatting, strong argumentation, and no redundancy.\n",
    "\"\"\"\n",
    "\n",
    "def safe_invoke(llm, query: str, system_role: str, context: str = \"\") -> str:\n",
    "    \"\"\"Unified LLM call enforcing safety and academic tone.\"\"\"\n",
    "    system_map = {\n",
    "        \"orchestrator\": SYSTEM_ORCHESTRATOR,\n",
    "        \"analyzer\": SYSTEM_ANALYZER,\n",
    "        \"planner\": SYSTEM_PLANNER,\n",
    "        \"writer\": SYSTEM_WRITER,\n",
    "        \"critic\": SYSTEM_CRITIC,\n",
    "        \"finalizer\": SYSTEM_FINALIZER,\n",
    "    }\n",
    "\n",
    "    system_prompt = system_map.get(system_role.lower(), system_role)\n",
    "    prompt = f\"\"\"\n",
    "System Role:\n",
    "{system_prompt}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User query:\n",
    "{query}\n",
    "\n",
    "Respond academically, factually, and concisely.\n",
    "    \"\"\"\n",
    "    return llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f589f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uploaded_documents(upload_folder=\"./notebooks/uploads\"):\n",
    "    \"\"\"Loads and embeds uploaded PDFs, TXTs, DOCXs.\"\"\"\n",
    "    print(\"üìÇ Loading uploaded documents...\")\n",
    "    files = [f for f in os.listdir(upload_folder) if f.lower().endswith((\".pdf\", \".txt\", \".docx\"))]\n",
    "    docs = []\n",
    "    for file in files:\n",
    "        path = os.path.join(upload_folder, file)\n",
    "        if file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(path)\n",
    "        elif file.endswith(\".txt\"):\n",
    "            loader = TextLoader(path)\n",
    "        else:\n",
    "            loader = UnstructuredWordDocumentLoader(path)\n",
    "        loaded = loader.load()\n",
    "        vectordb.add_documents(filter_complex_metadata(loaded))\n",
    "        docs.extend(loaded)\n",
    "    print(f\"‚úÖ {len(docs)} uploaded docs indexed.\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "def route_query(state: AgentState):\n",
    "    query = state.get(\"query\", \"\")\n",
    "    if is_out_of_scope(query):\n",
    "        state[\"intent\"] = \"blocked\"\n",
    "        state[\"final\"] = \"‚ö†Ô∏è This question is out of academic scope.\"\n",
    "    return state\n",
    "\n",
    "    state[\"intent\"] = safe_invoke(orchestrator, query, \"orchestrator\").strip().lower()\n",
    "    print(f\"üß≠ Intent classified as: {state['intent']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def general_answer(state: AgentState):\n",
    "    query = state[\"query\"]\n",
    "    state[\"final\"] = safe_invoke(plan_llm, query, \"General academic explanation\")\n",
    "    print(\"üí¨ General answer complete.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def analyzer_collect(state: AgentState):\n",
    "    \"\"\"Academic content from Arxiv (main)\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    print(\"üîç Searching arXiv for relevant preprints...\")\n",
    "    try:\n",
    "        loader = ArxivLoader(query=query, load_max_docs=3)\n",
    "        docs = loader.load()\n",
    "        if not docs:\n",
    "            state[\"context\"] = \"No academic sources found.\"\n",
    "            return state\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        chunks = splitter.split_documents(docs)\n",
    "        vectordb.add_documents(chunks)\n",
    "        retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "        top_docs = retriever.invoke(query)\n",
    "        state[\"context\"] = \"\\n\\n\".join([d.page_content for d in top_docs])\n",
    "        print(f\"üìö {len(chunks)} arXiv chunks added.\")\n",
    "    except Exception as e:\n",
    "        state[\"context\"] = f\"Error loading Arxiv: {e}\"\n",
    "    return state\n",
    "\n",
    "def local_doc_search(state: AgentState):\n",
    "    query = state[\"query\"]\n",
    "    print(\"üìÅ Searching uploaded docs...\")\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "    docs = retriever.invoke(query)\n",
    "    state[\"context\"] = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    print(f\"üìò Retrieved {len(docs)} local docs.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def list_documents(state: AgentState):\n",
    "    \"\"\"Return a list of the most relevant document summaries.\"\"\"\n",
    "    query = state.get(\"query\", \"\")\n",
    "    print(\"üìë Retrieving top documents...\")\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "    docs = retriever.invoke(query)\n",
    "\n",
    "    if not docs:\n",
    "        state[\"final\"] = \"‚ö†Ô∏è No relevant documents found.\"\n",
    "        return state\n",
    "\n",
    "    summaries = \"\\n\\n\".join([\n",
    "        f\"üìÑ {i+1}. {d.page_content[:300]}...\"\n",
    "        for i, d in enumerate(docs)\n",
    "    ])\n",
    "    state[\"final\"] = f\"Top 5 relevant documents:\\n\\n{summaries}\"\n",
    "    print(\"üìÑ Generated top 5 relevant document list.\")\n",
    "    return state\n",
    "\n",
    "def plan_writer(state: AgentState):\n",
    "    query, context = state[\"query\"], state.get(\"context\", \"\")\n",
    "    state[\"plan\"] = safe_invoke(plan_llm, query, \"Academic plan generator\", context)\n",
    "    print(\"üìù Plan written.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def draft_writer(state: AgentState):\n",
    "    plan = state[\"plan\"]\n",
    "    state[\"draft\"] = safe_invoke(draft_llm, plan, \"Essay writer\")\n",
    "    print(\"‚úçÔ∏è Draft complete.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def critic_agent(state: AgentState):\n",
    "    draft = state[\"draft\"]\n",
    "    state[\"critique\"] = safe_invoke(critic_llm, draft, \"Academic critic\")\n",
    "    print(\"üßæ Critique done.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def final_drafter(state: AgentState):\n",
    "    draft = state[\"draft\"]\n",
    "    state[\"final\"] = safe_invoke(final_llm, draft, \"Academic finalizer\")\n",
    "    vectordb.add_texts([state[\"final\"]])\n",
    "    print(\"‚úÖ Final draft ready.\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffda847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Graph Definition ---\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Existing nodes\n",
    "graph.add_node(\"route_query\", route_query)\n",
    "graph.add_node(\"general_answer\", general_answer)\n",
    "graph.add_node(\"analyzer_collect\", analyzer_collect)\n",
    "graph.add_node(\"local_doc_search\", local_doc_search)\n",
    "graph.add_node(\"list_documents\", list_documents)\n",
    "graph.add_node(\"plan_writer\", plan_writer)\n",
    "graph.add_node(\"draft_writer\", draft_writer)\n",
    "graph.add_node(\"critic_agent\", critic_agent)\n",
    "graph.add_node(\"final_drafter\", final_drafter)\n",
    "\n",
    "def route_decision(state):\n",
    "    intent = state.get(\"intent\", \"\")\n",
    "    query = state.get(\"query\", \"\").lower()\n",
    "\n",
    "    if intent == \"blocked\":\n",
    "        return END\n",
    "    elif intent == \"general\":\n",
    "        return \"general_answer\"\n",
    "    elif \"list\" in query or \"show\" in query or \"papers\" in query:\n",
    "        return \"list_documents\"\n",
    "    elif os.listdir(\"./notebooks/uploads\"):\n",
    "        return \"local_doc_search\"\n",
    "    else:\n",
    "        return \"analyzer_collect\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"route_query\",\n",
    "    route_decision,\n",
    "    {\n",
    "        \"general_answer\": \"general_answer\",\n",
    "        \"list_documents\": \"list_documents\",\n",
    "        \"local_doc_search\": \"local_doc_search\",\n",
    "        \"analyzer_collect\": \"analyzer_collect\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "graph.add_edge(\"local_doc_search\", \"list_documents\")\n",
    "graph.add_edge(\"analyzer_collect\", \"list_documents\")\n",
    "graph.add_edge(\"list_documents\", \"plan_writer\")\n",
    "graph.add_edge(\"plan_writer\", \"draft_writer\")\n",
    "graph.add_edge(\"draft_writer\", \"critic_agent\")\n",
    "graph.add_edge(\"critic_agent\", \"final_drafter\")\n",
    "graph.add_edge(\"final_drafter\", END)\n",
    "graph.add_edge(\"general_answer\", END)\n",
    "\n",
    "graph.set_entry_point(\"route_query\")\n",
    "app = graph.compile()\n",
    "app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180aa744",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    load_uploaded_documents(\"./notebooks/uploads\")\n",
    "    query = input(\"üîç Enter your academic question: \")\n",
    "    state = {\"query\": query}\n",
    "    final_state = app.invoke(state)\n",
    "    print(\"\\nüéì --- FINAL OUTPUT ---\")\n",
    "    print(final_state[\"final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"query\": \"Who developed the first generative AI model?\"}\n",
    "final_state = app.invoke(state)\n",
    "print(\"\\n--- RESULT 1: General Question ---\")\n",
    "print(final_state[\"final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"query\": \"5 Researches about GenAI and Agentic AI\"}\n",
    "final_state = app.invoke(state)\n",
    "print(\"\\n--- RESULT 2: Research Question ---\")\n",
    "print(final_state[\"final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1f6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"query\": \"List 5 papers about large language models and reinforcement learning\"}\n",
    "final_state = app.invoke(state)\n",
    "print(\"\\n--- RESULT 3: List Documents ---\")\n",
    "print(final_state[\"final\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
